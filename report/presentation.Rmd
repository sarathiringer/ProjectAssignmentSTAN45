---
title: 'Investigating discrimination bias in \newline predictive modelling'
author:
  - Sara Thiringer
  - Jonathan Rittmo
date: "26/10/2020"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(summarytools)
library(tidyverse)
library(fairmodels)
library(knitr)
library(kableExtra)
library(DALEXtra)

compas <- fairmodels::compas
COMPAS <- filter(compas, Ethnicity == "African_American" | Ethnicity == "Caucasian") %>% 
  rename(Below25 = Age_Below_TwentyFive) %>% 
  rename(Above45 = Age_Above_FourtyFive)
#compas$Two_yr_Recidivism <- as.factor(ifelse(compas$Two_yr_Recidivism == '1', '0', '1'))
COMPAS$Ethnicity <- droplevels(COMPAS$Ethnicity)


# split <- initial_split(COMPAS, prop = 0.8, strata = "Two_yr_Recidivism")
# compas_train <- training(split)
 y_numeric <- as.numeric(COMPAS$Two_yr_Recidivism)-1

```



## Background: The Problem

In recent years, many scandalous examples have shown that statistical models trained on large amounts of data can "act" discriminatory. Examples include:

- Adds of high-income jobs being shown less frequently to women, presumable becasue they've been predicted to be less interested or suitable^[@datta_automated_2015] 

- Black people's health status being underestimated, leading to inappropriate healtch care measures^[@obermeyer_dissecting_2019]

- Black people begin predicted a higher risk for crime recidivism, leading to higher penalties^[ProPublica (2016)]

## Project Aims

* How can we quantify fairness in order to be able to evaluate algorithmic fairness?
* What methods are available to increase algorithmic fairness? In what type of
  situations do they apply? (i.e. In what kind of situations can we expect them to
  be successful?)

## Background: Why Discrimination Bias?

- Correlation between outcome $y$ and protected charateristic $x_p$
- Correlation between important predictors $\boldsymbol{x}_i$ and protected carachteristic $x_p$
- Undersampling of groups with protected protected carachteristic $x_p$

## Possible Solutions

**Pre-Processing**  | **Training** | **Prediction**
------ | ------|-------------------------------------------
Resampling | Penalty | Threshold
Mapping  | Model bias | adjustments
Altering labels | Tuning for fairness | Alter predictions

We've chosen to work with resampling and threshold adjustment. 

## Possible Goals

Demographic parity

$$
P(Y=1 | X=1) = P(Y=1 | X=0)
$$

Equalized odds

$$
P(G=1|X=0, Y=1) = P(G=1|X=1, Y=1)
$$

## 

\small
```{r desc, results='asis', echo=FALSE}

dfSummary(COMPAS, silent = TRUE, graph.col = FALSE, valid.col = FALSE, na.col = FALSE  )

```
\normalsize

## Models

Model  | Tuning 
------ | -------------------------------------------------
Random Forest | Predictors at each split 
Artificial neural net  | Number of hidden nodes 
Logistic ridge regression | Penalisation 
K-nearest neighbour (left out) | Number of neighbours
AdaBoost | Predictors at each split

## Accuracy and Fairness for the Initial Models

```{r fap1, echo=FALSE, out.width='100%', results='hide'}

load("models/fobject1.Rdata")
fap <- performance_and_fairness(fobject1, fairness_metric = "STP",
                                performance_metric = "accuracy")
x <- plot(fap)
x +
  ggtitle("") +
  labs(x = "Accuracy", y = "Inversed parity loss (demographic parity)", color = "Model")
```

## Disparate Impact Removal

## Resampling

```{r joint-org, results='asis', echo=FALSE}

kable(table(COMPAS$Two_yr_Recidivism, COMPAS$Ethnicity), caption = "Joint distribution of Ethnicity and Recidivism",
      format = "latex", booktabs = T)%>%
  kable_styling(latex_options = c("hold_position")) %>% 
  add_footnote(label = 'Note: 1 = Recidivism', notation = "none")

```

## Uniform Resampling

```{r joint-uni, results='asis', echo=FALSE}
uniform_indexes <- resample(protected = COMPAS$Ethnicity,
                            y = y_numeric)

kable(table(COMPAS[uniform_indexes,]$Two_yr_Recidivism, COMPAS[uniform_indexes,]$Ethnicity), caption = "Joint distribution of Ethnicity and Recidivism, uniform resampling",
      format = "latex", booktabs = T)%>%
  kable_styling(latex_options = c("hold_position")) %>% 
  add_footnote(label = 'Note: 1 = Recidivism', notation = "none")

```

## Preferential Resampling

- Very similar to uniform 
- Borderline observations skipped or duplicated more often
- Evaluated by logistic regression

## Comparison

```{r fap-all, echo=FALSE, out.width='100%', fig.height=6, results='hide'}

load("models/fobject_all.Rdata")
fap <- performance_and_fairness(fobject_all, fairness_metric = "STP",
                                performance_metric = "accuracy")
x <- plot(fap)
x + 
  ggtitle("") +
  labs(x = "Accuracy", y = "Inversed parity loss (demographic parity)", color = "Model") +
  theme(legend.position = "",
        axis.title=element_text(size=14))
```

## Cutoff adjustment 

```{r cutoff-rf, echo=FALSE, out.width='100%',  results='hide', message=FALSE}

load("models/fobject_co.Rdata")

plot(ceteris_paribus_cutoff(fobject_co,
                            subgroup = "African_American",
                            fairness_metrics = c("TPR","STP"))) +
  ggtitle("", subtitle = "") +
  labs(x = "Cutoff value", y = "Parity loss", color = "Parity loss metric") +
  scale_color_discrete(labels = c("Demographic parity", "Equalised odds")) 
  
```

## Comparing cutoff models

```{r fap-rf-comp, echo=FALSE, out.width='100%',  results='hide'}

load("models/fo_comp.Rdata")

fap <- performance_and_fairness(fo_comp, fairness_metric = "STP")
plot(fap) +
  ggtitle("") +
  labs(x = "Accuracy", y = "Inversed parity loss (demographic parity)", color = "Model") 
  
```

## Evaluation on test data - comparison

```{r fap-test, echo=FALSE, out.width='100%', fig.height=6,  results='hide'}

load("models/fobject_test.Rdata")

fap <- performance_and_fairness(fobject_test, fairness_metric = "STP")
plot(fap) +
  ggtitle("") +
  labs(x = "Accuracy", y = "Inversed parity loss (demographic parity)", color = "Model") +
  theme(legend.position = "")
  
```


## Final Model Performance

```{r modelperf, results='asis', echo = FALSE}
load("models/rf_test_exp_resa_uni.Rdata")
x <- model_performance(rf_test_exp_resa_uni)
x <- data.frame(x[["measures"]]) %>% 
  select(-f1) %>% round(digits = 3)
kable(x, caption = "Performance",
      format = "latex", booktabs = T)%>%
  kable_styling(latex_options = c("hold_position"))

```


## Conclusions


